quarkus.http.port = 8080

# PostgreSQL database automatically created by Dev Services with the following settings
quarkus.devservices.enabled = true
quarkus.datasource.devservices.port = 5432
quarkus.datasource.devservices.db-name = rag
quarkus.datasource.devservices.username = rag
quarkus.datasource.devservices.password = rag
# Run Flyway database schema migrations automatically
quarkus.flyway.migrate-at-start = true

# The dimension of the embedding vectors. This has to be the same as the dimension of vectors produced by the embedding model that you use.
quarkus.langchain4j.pgvector.dimension = 768
# The table name for storing embeddings - see V1__create_schema.sql
quarkus.langchain4j.pgvector.table = embedding_item
# Used if the table and index are created automatically by langchain4j
quarkus.langchain4j.pgvector.use-index = true
quarkus.langchain4j.pgvector.index-list-size= 100

quarkus.langchain4j.log-requests = true
quarkus.langchain4j.log-responses = true
# The temperature to use for the chat model. Temperature is a value between 0 and 1, where lower values make the model more deterministic and higher values make it more creative.
quarkus.langchain4j.temperature = 0.2
# Global timeout for requests to LLM APIs
quarkus.langchain4j.timeout = 60s

# The chat model to use. In case of Ollama, llama3.1 is the default chat model.
quarkus.langchain4j.ollama.chat-model.model-id = gpt-oss
# The format to return a response in. Format can be json or a JSON schema, or text; in this application, we use text.
quarkus.langchain4j.ollama.chat-model.format = text
# In case of Ollama, nomic-embed-text is the default model used for text embeddings.
quarkus.langchain4j.ollama.embedding-model.model-id = nomic-embed-text

# The location of the documents to be processed; can be relative or absolute path.
rag.document.location = ./documents
# The document loader scheduler period; default is 60 seconds
rag.document.loader.scheduler.period = 10s
# The maximum length (in characters) of a document segment used during ingestion. Default is 550 characters.
rag.embedding.max-segment-size = 500
# The maximum number of characters that can overlap between two segments. Default is 25 characters.
rag.embedding.max-overlap-size = 25
# The maximum number of retrieved embeddings when querying for relevant documents. Default is 200.
rag.retrieval.max-results = 200
# The minimum cosine similarity score for a document to be considered relevant during retrieval. Score ranges between 0 (no similarity) and 1 (identical). Default is 0.8.
rag.retrieval.min-score = 0.8
